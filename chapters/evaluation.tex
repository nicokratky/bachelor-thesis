\chapter{Evaluation}
\label{ch:evaluation}

This chapter first introduces the setup that was used for evaluating the different elasticity strategies. Then the results of different tests are presented and discussed.

\section{Testsetup}
\label{sec:testsetup}

In order to test the different elasticity strategies a test environment has to be set up. It was decided to create three virtual machines (VM) that will form a Kubernetes cluster. Because of its easy of use microk8s was chosen as distribution\footnote{\url{https://microk8s.io/}}. All three virtual machines were assigned 10 vCPUs and 10GB of memory. One VM acts as the Kubernetes control plane while the other two join the cluster as worker nodes.

Everything that was deployed into the Kubernetes cluster was built using the infrastructure as code (IaC) tool HashiCorp Terraform\footnote{\url{https://www.terraform.io/}}. This enables rapid changes and reproducibility. Deployed resources include the kube-prometheus-stack\footnote{\raggedright\url{https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack}} for monitoring, the k8ssandra-operator\footnote{\url{https://docs.k8ssandra.io/components/k8ssandra-operator/}} for managing k8ssandra clusters and a definition for a k8ssandra cluster. Additionally, the in \cref{sec:metrics} mentioned Grafana dashboards are also deployed using Terraform.

\Cref{lst:k8c} illustrates a minimal definition of a 3 node k8ssandra cluster. Each node has resource limits of 800 millicpu and 6000MB of memory and 3GiB storage space.

\begin{lstlisting}[caption={Minimal example of a K8ssandraCluster definition.},
                label=lst:k8c,
                captionpos=b,
                float]
apiVersion: k8ssandra.io/v1alpha1
kind: K8ssandraCluster
metadata:
  name: polaris-test-cluster
  namespace: k8ssandra
spec:
  cassandra:
    resources:
      limits:
        cpu: 800m
        memory: 6000M
    datacenters:
      - metadata:
          name: dc1
        size: 3
        storageConfig:
          cassandraDataVolumeClaimSpec:
            resources:
              requests:
                storage: 3Gi
\end{lstlisting}

\section{Benchmarks}

In the following sections, different test scenarios will be discussed. To let k8ssandra experience load, the built-in stress testing tool \texttt{cassandra-stress} was used\footnote{\raggedright\url{https://cassandra.apache.org/doc/stable/cassandra/tools/cassandra_stress.html}}.

\subsection{Stress Testing}
\label{sec:stress-testing}

To set a baseline, three different k8ssandra cluster setups have been stress tested using \texttt{cassandra-stress}. The amount of write requests that the tool will make is set to be 1000000, the exact call is listed in \cref{lst:stress-1000000writes}. These cluster setups merely differ in the cluster size, thus the amount of nodes. All clusters were provisioned with limits of 2 CPUs and 6GB of memory.

\begin{lstlisting}[caption={},
                    captionpos=b,
                    label=lst:stress-1000000writes,
                    float]
./cassandra-stress write n=1000000 -mode native cql3 \
    user='USERNAME' password='PASSWORD'
\end{lstlisting}

The results of these tests are depicted in \cref{fig:stress-1000000writes-1node,fig:stress-1000000writes-2node,,fig:stress-1000000writes-3node}. The write throughput increases with the amount of nodes, but not linearly. This, however, was to be expected as \texttt{cassandra-stress} does not partition data in way that favours linear scalability. The average write throughputs of these different clusters can be seen in \cref{tab:stress-1000000writes-ops}.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Cluster size} & \textbf{operations/s} & \textbf{Time to complete} \\ \hline
1                     & 12514                 & 2m38s                     \\ \hline
2                     & 13142                 & 1m57s                     \\ \hline
3                     & 14318                 & 1m50s                     \\ \hline
\end{tabular}
\caption{Average write throughput for different k8ssandra clusters. With increasing cluster size the throughput also increases}
\label{tab:stress-1000000writes-ops}
\end{table}

\begin{figure}
    \centering
    \input{figures/plots/stress-1000000writes-1node.pgf}
    \caption{Stress test of 1 node with 1000000 writes}
    \label{fig:stress-1000000writes-1node}
\end{figure}

\begin{figure}
    \centering
    \input{figures/plots/stress-1000000writes-2node.pgf}
    \caption{Stress test of 2 nodes with 1000000 writes}
    \label{fig:stress-1000000writes-2node}
\end{figure}

\begin{figure}
    \centering
    \input{figures/plots/stress-1000000writes-3node.pgf}
    \caption{Stress test of 3 nodes with 1000000 writes}
    \label{fig:stress-1000000writes-3node}
\end{figure}

\subsection{Vertical Elasticity Strategy}
\label{sec:evaluation-vertical-elasticity}

As mentioned in \cref{sec:vertical-elasticity} the vertical elasticity strategy adjusts the resource claims of k8ssandra according to its CPU and memory utilization.

As it can bee seen in \cref{fig:simple-limits-vertical} the elasticity strategy controller successfully changes the CPU and memory limits of the k8ssandra cluster once it is operational. \Cref{fig:utilization-vertical} shows the CPU and memory utilization that is used for triggering elasticity processes. Because the CPU utilization stays very low even after scaling takes place, it can be assumed that this metric was not a decisive factor. The memory utilization, however, changes notably. Before starting the elasticity strategy controller the actual memory utilization was off by \(>10\%\) from the target memory utilization. This triggers an elasticity event and the resources are adjusted proportionally.

Interestingly, during reconsiliation the exposed metrics of k8ssandra are not very meaningful. During this process utilization values of far more than 100\% are exposed by the metrics controller. In order to keep the diagram clean, these nonsense-metrics have been filtered out. The reconsiliation process is marked red in \cref{fig:utilization-vertical}.

This elasticity strategy mirrors real-life scenarios. The advantage lies in being able to scale down when demand and therefore CPU and memory utilization is low, thus potentially reducing cost. This obviously only applies when not using dedicated resources.

\begin{figure}
    \centering
    \input{figures/plots/simple-limits-vertical-controller-1node-30min.pgf}
    \caption{Adjustment of CPU and memory limits by the vertical elasticity strategy controller}
    \label{fig:simple-limits-vertical}
\end{figure}

\begin{figure}
    \centering
    \input{figures/plots/utilization-vertical-controller-1node-20min.pgf}
    \caption{Utilization of CPU and memory during an vertical scaling action}
    \label{fig:utilization-vertical}
\end{figure}

\subsection{Horizontal Elasticity Strategy}
\label{sec:evaluation-horizontal-elasticity}

The horizontal elasticity strategy controller scales the target k8ssandra cluster horizontally, thus adding nodes as demand increases. Demand is measured as write throughput by the metrics controller as described in \cref{sec:metrics-average-write-utilization}.

As in the example stress tests discussed in \cref{sec:stress-testing}, \texttt{cassandra-stress} was used to generate load on the target k8ssandra cluster. During this load generation process, the horizontal elasticity controller was running. The target write load per node was defined in the SLO mapping as 5000. Depicted in \cref{fig:horizontal-elasticity} is the average write load per node metric and the corresponding node count during the testing process. It can be seen that the node count does not increase immediatly when the scaling action takes place. That is because when the k8ssandra CRD is updated by the elasticity strategy controller, first the \texttt{k8ssandra-operator} has to recognize the made changes and adjust the configuration accordingly. When the second k8ssandra node is successfully scheduled it still needs time to start and finally register in the cluster. The final action is the Cassandra reconciliation process.

At approximately 290s a sudden drop in the metric can be observed. This is the point when the scaling action becomes effective and the k8ssandra node is ready. Then, after another few moments the metric drops under the set boundary of 5000. Tests of this kind are difficult to run over an extended period of time because of a limitation of \texttt{cassandra-stress}. When the load generator is started, it collects all available nodes in the cluster through Cassandra's communication protocol \texttt{Gossip}. \texttt{Gossip} is the protocol that Cassandra uses internally for its nodes to communicate with each other\footnote{\raggedright\url{https://docs.datastax.com/en/cassandra-oss/3.x/cassandra/architecture/archGossipAbout.html}}. While \texttt{cassandra-stress} is running, new nodes are not recognized and requests are therefore not sent to added nodes. Possible solutions to this will be discussed in \cref{ch:conclusion}.

\begin{figure}
    \centering
    \input{figures/plots/horizontal-elasticity.pgf}
    \caption{Average write load per node and amount of nodes during a horizontal scaling action}
    \label{fig:horizontal-elasticity}
\end{figure}

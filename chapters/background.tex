\chapter{Background}
\label{ch:background}

Over the last years and decades cloud computing emerged as a paradigm which allows customers to receive compute power in a pay-as-you-go and on-demand manner.

This chapter introduces some terminology and concepts that are used throughout this thesis. First the cloud computing concepts are defined and then the used framework is introduced.

\section{Elasticity in Cloud Computing}
\label{sec:elasticity}

Elasticity is one of the core concepts that solves a big problem of cloud computing: providing limited resources for potentially unlimited use. The solution is to scale workloads up and down as needed, to claim resources when bigger load is experienced and release resources when they are not needed, therefore making them available to other workloads.

The term elasticity in computing is conceptually similiar to the term in physics. Wikipedia, for example, defines elasticity as follows: ``In physics and materials science, elasticity is the ability of a body to resist a distorting influence and to return to its original size and shape when that influence or force is removed. Solid objects will deform when adequate loads are applied to them; if the material is elastic, the object will return to its initial shape and size after removal.''\footnote{\url{https://en.wikipedia.org/wiki/Elasticity_(physics)}}

The formula - which takes a more mathematical approach - of elasticity can be defined as \[ e(Y, X) = \diff{Y}{X} \frac{X}{Y}, \] where \(e(Y, X)\) is the elasticity of \(Y\) with respect to \(X\) \cite{dustdarPrinciplesElasticProcesses2011}.

To illustrate this imagine an application that serves some content to its customers. These customers typically interact with the application during the day. This means that the application experiences significantly less load during the night. Once people wake up in the morning the load rises until it peaks in the afternoon. Then the load falls again when people go to sleep in the evening. Using this example it can be seen in \cref{fig:elasticity-application-no-scaling} that during the night the resources of the application are overprovisioned and during the day the resoures are underprovisioned.

\begin{figure}
    \centering
    \input{figures/plots/application-no-scaling.pgf}
    \caption{Resource demand and supply for a website during a typical day with no elastic processes.}
    \label{fig:elasticity-application-no-scaling}
\end{figure}

If the concept of elasticity is applied to this example, resources can be released during the night (so called \textit{scale-in}) and more resources can be claimed as they are needed during the day (so called \textit{scale-out}). This is illustrated in \cref{fig:elasticity-application-scaling}.

\begin{figure}
    \centering
    \input{figures/plots/application-scaling.pgf}
    \caption{Resource demand and supply for a website during a typical day with elastic processes.}
    \label{fig:elasticity-application-scaling}
\end{figure}

Elasticity has multiple properties which are interdependent: resource elasticity, cost elasticity and quality elasticity \cite{dustdarPrinciplesElasticProcesses2011}. These properties are discussed in the following sections.

\subsection{Resource Elasticity}

The resource dimension of elasticity is mistakenly often used synonymously with elasticity. Meanwhile, resource elasticity is defined as the degree to which a system is able to adapt to workload changes by claiming and releasing resources autonomously, such that the resource supply matches the current demand as closely as possible \cite{herbstElasticityCloudComputing2013}. Another way to think of this is ``on the fly'' adaptions to load variations \cite{al-dhuraibiElasticityCloudComputing2018}.

What makes this definition easily mistaken, is that it solely considers the aquired resources and not the consequently incurred costs or changing quality.

% The ability to acquire resources as you need them and release resources when you no longer need them \cite{ElasticityAWSWellArchitected}.

\subsection{Cost Elasticity}

Cost elasticity uses cost as its main factor for elasticity decisions. One of the most popular models that build upon cost elasticity is \textit{utility computing}, also known as the \textit{pay-as-you-go} pricing model.

Amazon Web Services uses this elasticity dimension in their EC2 Spot Instance\footnote{\url{https://aws.amazon.com/ec2/spot/}}. AWS provides its unused compute capacity at a large discount to its customers. But because these capacities are volatile, the prices are not fixed but are provided through a bidding process. The potential customer tells AWS their maximum price they are willing to pay. The customer can then run their instances as long as their bidding price is smaller than AWS's Spot Instance price.

\subsection{Quality Elasticity}

Similiar to the already discussed dimensions, quality elasticity is defined as letting software services adapt their mode of operastion to current operating conditions by providing results of varying output quality \cite{larssonQualityElasticityImprovedResource2019}. This means that when resource supply is low, the output quality also may be low. Likewise, if resource supply is sufficient, the output quality will also be high.

\section{Service Level Agreements and Service Level Objectives}

In order to deliver services up to a certain standard, agreements between the service provider, typically the cloud provider, and the service consumers are made - so called \textit{Service Level Agreements (SLA)} \cite{emeakarohaLowLevelMetrics2010d}. Contained inside these SLAs are \textit{Service Level Objectives (SLO)}, which are a ``commitment to maintain a particular state of the service in a given period'' \cite{kellerWSLAFrameworkSpecifying2003}.

SLOs are measurable values, e.g. an applications CPU usage or memory consumption, that have a specified operating target. In the case that this value is violated the supporting infrastructure of the application has to be either increased or decreased. This process of increasing or decreasing resources is called elasticity, which was further discussed in \cref{sec:elasticity}.

\section{Polaris SLO Framework}
\label{sec:polaris}

The Polaris SLO Framework\footnote{\url{https://polaris-slo-cloud.github.io/polaris-slo-framework/}} is a framework that provides a way to bring high-level SLOs to the cloud. It tries to solve the limitation that modern cloud cloud providers only offer rudimentary support for high-level SLOs and customers often need to manually map them to low-level metrics such as CPU usage or memory consumption \cite{pusztaiSLOScriptNovel2021}.

The authors of this framework introduce the concept of \textit{elasticity strategies}. A elasticity strategy is defined as any sequency of actions that adjust the amount of resources provisioned for a workload, their type or the workload configuration. The workload configuration adjustment is especially noteworthy, because workloads handled by Polaris can be affected in all three elasticity dimensions.

Another unique feature of Polaris is its object model, which allows for orchestrator independence. This is achieved by encapsulating all data that is transmitted to the orchestrator into a \texttt{ApiObject} type.

Decoupling SLOs from elasticity strategies is also a feature that Polaris provides. Tight coupling is a charactaristic that is even observed in industry standard scaling mechanisms such as Kubernetes' Horizontal Pod Autoscaler\footnote{\raggedright\url{https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/}}. This autoscaler provides a CPU usage SLO which can only trigger horizontal elasticity, thus adding or removing CPU resources. To achieve this decoupling, Polaris utilizes an architecture that is depicted in \cref{fig:polaris-architecture}. This allows the controllers to focus on a single task, for example calculating SLO compliance. These individual components are then mapped using a SLO mapping type.

\begin{figure}
    \centering
    \incfig{polaris-architecture}
    \caption{Architecture of the Polaris SLO framework. Metrics controllers, elasticity strategy controllers and targets are decoupled and mapped using a SLO mapping.}
    \label{fig:polaris-architecture}
\end{figure}

\section{k8ssandra}
\label{sec:k8ssandra}

Cassandra is a popular wide-column store NoSQL database that was initially developed at Facebook and later integradet into the Apache Software Foundation\footnote{\url{https://cassandra.apache.org/_/cassandra-basics.html}\label{fn:cassandra-basics}}. Its main features include being easily horizontally scalable, being fully distributed and its schema-less data approach.

Being distributed means, that Cassandra is comprised of a set of nodes. Each nodes tasks and responsibilities are identical. Data is partitioned using a partition key and is replicated between nodes. How many times data is replicated is determined by the \textit{replication factor} or \(RF\). \(RF = 3\) would therefore mean that each piece of data must exist on 3 nodes.

Distributed data also comes with a certain cost. These drawbacks are formulated in the CAP theorem \cite{foxHarvestYieldScalable1999a}. CAP stands for consistency, availability and partition tolerance and the theorem states that databases which handle data in a distributed way can only provide two of these three guarantees. Cassandra, per default, is an AP database. This agreement, however, is configurable on a per-query basis. This means, that whatever consistency level is configured, it represents the minimum amount of nodes that must acknowledge a operation back to the query coordinator node to consider this operation successful.

Queries can be made to any node. Cassandra does not have a main node that takes queries, instead any node that a client connects to takes over the role of coordinator for this specific query. This coordinator node then is responsible for querying other nodes for data in other partitions. This also implies that Cassandra uses peer-to-peer communication between its nodes. This architecture is also depicted in \cref{fig:cassandra-architecture}.

\begin{figure}
    \centering
    \incfig{cassandra-architecture}
    \caption{Architecture of a 5 node Cassandra Cluster. Dotted lines represent possible communication paths.}
    \label{fig:cassandra-architecture}
\end{figure}

Another powerful feature, which makes this database particular interesting for this thesis, is its capabilities to scale. If the partition key is chosen wisely and the database is therefore able to distribute data evenly between nodes, then doubling the amount of nodes also doubles the throughput \footref{fn:cassandra-basics}

k8ssandra\footnote{\url{https://k8ssandra.io}} (pronounced: ``Kate'' +  ``Sandra'') is a open-source cloud-native distribution of Cassandra that is specifically made to run on Kubernetes. It includes several tools for providing a data API, backup/restore processes and automated database repairs. It also includes Kubernetes custom resource definitions (CRDs) to be able to easily deploy Cassandra databases. It also allows easy integration in existing observability and monitoring stacks such as the \texttt{kube-prometheus-stack}\footnote{\raggedright\url{https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack}}.
